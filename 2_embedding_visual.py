"""
2. –°–û–ó–î–ê–ù–ò–ï –ò –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –≠–ú–ë–ï–î–î–ò–ù–ì–û–í

–ß—Ç–æ –¥–µ–ª–∞–µ–º:
1. –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç (—Å–ª–æ–≤–∞) –≤ —á–∏—Å–ª–∞ (–≤–µ–∫—Ç–æ—Ä—ã)
2. –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —ç—Ç–∏ –≤–µ–∫—Ç–æ—Ä—ã, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏
3. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–∏—Å–∫ –ø–æ —Å–º—ã—Å–ª—É

–ê–Ω–∞–ª–æ–≥–∏—è:
–ö–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ/—Ç–µ–∫—Å—Ç ‚Üí —Ç–æ—á–∫–∞ –Ω–∞ –∫–∞—Ä—Ç–µ
–ü–æ—Ö–æ–∂–∏–µ —Ç–µ–∫—Å—Ç—ã ‚Üí –±–ª–∏–∑–∫–∏–µ —Ç–æ—á–∫–∏
–†–∞–∑–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã ‚Üí –¥–∞–ª–µ–∫–∏–µ —Ç–æ—á–∫–∏
"""

import pickle

try:
    with open('rag_data_step1.pkl', 'rb') as f:
        rag_data = pickle.load(f)

    print("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞")
    chunks = rag_data["chunks"]
    print(f"–†–∞–±–æ—Ç–∞–µ–º —Å {len(chunks)} —á–∞–Ω–∫–∞–º–∏")

except FileNotFoundError:
    print("‚ùå –§–∞–π–ª 'rag_data_step1.pkl' –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    print("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ 1_data_preparation.py")
    exit()

print("=" * 60)
print("–®–ê–ì 2: –°–û–ó–î–ê–ù–ò–ï –í–ï–ö–¢–û–†–ù–´–• –ü–†–ï–î–°–¢–ê–í–õ–ï–ù–ò–ô")
print("=" * 60)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —à–∞–≥–∞
# –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ —ç—Ç–æ –±—ã–ª –±—ã —Ñ–∞–π–ª –∏–ª–∏ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
chunks = rag_data["chunks"]
chunk_info = rag_data["chunk_info"]

print(f"–†–∞–±–æ—Ç–∞–µ–º —Å {len(chunks)} —á–∞–Ω–∫–∞–º–∏")

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
print("\n–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
print("(—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ)")

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω—É–∂–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
from sentence_transformers import SentenceTransformer
import numpy as np

# –ë–µ—Ä–µ–º –º–∞–ª–µ–Ω—å–∫—É—é, –Ω–æ —Ö–æ—Ä–æ—à—É—é –º–æ–¥–µ–ª—å
# 'all-MiniLM-L6-v2' - 384-–º–µ—Ä–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã, –±—ã—Å—Ç—Ä–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
model = SentenceTransformer('all-MiniLM-L6-v2')

print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
print(f"–ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä—ã —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é {model.get_sentence_embedding_dimension()}")

# –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤
print("\n–°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞...")
print("–≠—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –ø–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ '—è–∑—ã–∫ —á–∏—Å–µ–ª'")

embeddings = model.encode(chunks)

print("‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ–∑–¥–∞–Ω—ã!")
print(f"–†–∞–∑–º–µ—Ä –º–∞—Å—Å–∏–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {embeddings.shape}")
print(f"  ‚Üí {embeddings.shape[0]} —á–∞–Ω–∫–æ–≤")
print(f"  ‚Üí {embeddings.shape[1]} —á–∏—Å–µ–ª –≤ –∫–∞–∂–¥–æ–º –≤–µ–∫—Ç–æ—Ä–µ")

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
print("\nüëÄ –ü—Ä–∏–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (–ø–µ—Ä–≤—ã–µ 10 —á–∏—Å–µ–ª –∏–∑ 384):")
sample_embedding = embeddings[0][:10]
print(f"[{', '.join(f'{x:.3f}' for x in sample_embedding)}...]")
print("... –∏ –µ—â–µ 374 —á–∏—Å–ª–∞")


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ö–æ–¥—Å—Ç–≤–∞
def calculate_similarity(vec1, vec2):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è –≤–µ–∫—Ç–æ—Ä–∞–º–∏
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å–ª–æ –æ—Ç -1 –¥–æ 1:
    1 = –∞–±—Å–æ–ª—é—Ç–Ω–æ –ø–æ—Ö–æ–∂–∏
    0 = –Ω–µ —Å–≤—è–∑–∞–Ω—ã
    -1 = –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã
    """
    # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ = (A¬∑B) / (|A| * |B|)
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)

    # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
    if norm1 == 0 or norm2 == 0:
        return 0

    similarity = dot_product / (norm1 * norm2)
    return similarity


# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏
print("\nüîç –°–†–ê–í–ù–ò–í–ê–ï–ú –ü–û–•–û–ñ–ï–°–¢–¨ –ß–ê–ù–ö–û–í:")

# –í—ã–±–∏—Ä–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞–Ω–∫–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
print("\n–î–∞–≤–∞–π—Ç–µ —Å—Ä–∞–≤–Ω–∏–º —Ç—Ä–∏ —á–∞–Ω–∫–∞:")
print("1. –û –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏")
print("2. –û –≥–ª—É–±–æ–∫–æ–º –æ–±—É—á–µ–Ω–∏–∏")
print("3. –û —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞—Ö")

# –ù–∞—Ö–æ–¥–∏–º –ø—Ä–∏–º–µ—Ä—ã –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
ml_chunks = []
dl_chunks = []
transformer_chunks = []

for i, chunk in enumerate(chunks):
    chunk_lower = chunk.lower()
    if "–º–∞—à–∏–Ω–Ω" in chunk_lower:
        ml_chunks.append(i)
    if "–≥–ª—É–±–æ–∫" in chunk_lower:
        dl_chunks.append(i)
    if "—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä" in chunk_lower:
        transformer_chunks.append(i)

# –ë–µ—Ä–µ–º –ø–æ –æ–¥–Ω–æ–º—É –ø—Ä–∏–º–µ—Ä—É –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
if ml_chunks and dl_chunks and transformer_chunks:
    ml_idx = ml_chunks[0]
    dl_idx = dl_chunks[0]
    transformer_idx = transformer_chunks[0]

    print(f"\n–ß–∞–Ω–∫ {ml_idx + 1}: {chunks[ml_idx][:80]}...")
    print(f"–ß–∞–Ω–∫ {dl_idx + 1}: {chunks[dl_idx][:80]}...")
    print(f"–ß–∞–Ω–∫ {transformer_idx + 1}: {chunks[transformer_idx][:80]}...")

    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ
    print("\nüìê –í–´–ß–ò–°–õ–Ø–ï–ú –°–•–û–î–°–¢–í–û:")

    sim_ml_dl = calculate_similarity(embeddings[ml_idx], embeddings[dl_idx])
    print(f"–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ ‚Üî –ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ: {sim_ml_dl:.3f}")

    sim_ml_transformer = calculate_similarity(embeddings[ml_idx], embeddings[transformer_idx])
    print(f"–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ ‚Üî –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã: {sim_ml_transformer:.3f}")

    sim_dl_transformer = calculate_similarity(embeddings[dl_idx], embeddings[transformer_idx])
    print(f"–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ ‚Üî –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã: {sim_dl_transformer:.3f}")

    print("\nüìä –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø:")
    print("–ë–ª–∏–∂–µ –∫ 1 ‚Üí –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏ –ø–æ —Å–º—ã—Å–ª—É")
    print("–ë–ª–∏–∂–µ –∫ 0 ‚Üí —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã")
    print("–ë–ª–∏–∂–µ –∫ -1 ‚Üí –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–µ —Ç–µ–º—ã")

    # –ß—Ç–æ –æ–∑–Ω–∞—á–∞—é—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüí° –ß–¢–û –≠–¢–û –ó–ù–ê–ß–ò–¢:")
    print(f"1. ML –∏ DL –∏–º–µ—é—Ç —Å—Ö–æ–¥—Å—Ç–≤–æ {sim_ml_dl:.3f} ‚Äî —ç—Ç–æ –ª–æ–≥–∏—á–Ω–æ,")
    print("   –≤–µ–¥—å –≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ ‚Äî —á–∞—Å—Ç—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")

    print(f"\n2. ML –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã: {sim_ml_transformer:.3f} ‚Äî —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã")
    print("   –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è —Ç–µ–º–∞, –ø–æ—ç—Ç–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–Ω—å—à–µ")

    print(f"\n3. DL –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã: {sim_dl_transformer:.3f} ‚Äî –≤—ã—à–µ, —á–µ–º —Å ML,")
    print("   –ø–æ—Ç–æ–º—É —á—Ç–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã ‚Äî —ç—Ç–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π,")
    print("   –∞ –≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏")

# –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –≠–ú–ë–ï–î–î–ò–ù–ì–û–í
print("\n" + "=" * 60)
print("–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø: –ö–ê–ö –í–´–ì–õ–Ø–î–Ø–¢ –ù–ê–®–ò –≠–ú–ë–ï–î–î–ò–ù–ì–ò")
print("=" * 60)

print("\n–ü—Ä–æ–±–ª–µ–º–∞: —É –Ω–∞—Å –≤–µ–∫—Ç–æ—Ä—ã –∏–∑ 384 —á–∏—Å–µ–ª")
print("–†–µ—à–µ–Ω–∏–µ: —É–º–µ–Ω—å—à–∏–º –¥–æ 2D –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")

# –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Å –ø–æ–º–æ—â—å—é PCA
from sklearn.decomposition import PCA

print("\n–ü—Ä–∏–º–µ–Ω—è–µ–º PCA (Principal Component Analysis)...")
print("PCA –Ω–∞—Ö–æ–¥–∏—Ç '–≥–ª–∞–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è' –≤ –¥–∞–Ω–Ω—ã—Ö")
print("384D ‚Üí 2D (–∫–∞–∫ –ø—Ä–æ–µ—Ü–∏—Ä–æ–≤–∞—Ç—å 3D –æ–±—ä–µ–∫—Ç –Ω–∞ 2D —ç–∫—Ä–∞–Ω)")

pca = PCA(n_components=2)
embeddings_2d = pca.fit_transform(embeddings)

print("‚úÖ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —É–º–µ–Ω—å—à–µ–Ω–∞!")
print(f"–¢–µ–ø–µ—Ä—å —É –Ω–∞—Å {embeddings_2d.shape[0]} —Ç–æ—á–µ–∫ –≤ 2D –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ")

# –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Å–∏–≤—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
import matplotlib.pyplot as plt

print("\n–°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é...")
plt.figure(figsize=(12, 8))

# –†–∞–∑–Ω—ã–µ —Ü–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —á–∞–Ω–∫–æ–≤
colors = []
labels = []

for i in range(len(chunks)):
    chunk_text = chunks[i].lower()

    if any(word in chunk_text for word in ["–º–∞—à–∏–Ω–Ω", "ml", "machine"]):
        colors.append('blue')
        labels.append('ML')
    elif any(word in chunk_text for word in ["–≥–ª—É–±–æ–∫", "deep", "–Ω–µ–π—Ä–æ–Ω"]):
        colors.append('green')
        labels.append('Deep Learning')
    elif any(word in chunk_text for word in ["—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä", "gpt", "bert"]):
        colors.append('red')
        labels.append('Transformers')
    elif any(word in chunk_text for word in ["rag", "retrieval"]):
        colors.append('purple')
        labels.append('RAG')
    else:
        colors.append('gray')
        labels.append('Other')

# –†–∏—Å—É–µ–º —Ç–æ—á–∫–∏
for i in range(len(embeddings_2d)):
    x, y = embeddings_2d[i]
    plt.scatter(x, y, color=colors[i], s=100, alpha=0.7)

    # –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–æ—á–∫–∏
    if i < 8:  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 8 –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        plt.text(x, y, f' {i + 1}', fontsize=9, alpha=0.8)

# –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–µ–Ω–¥—É
from matplotlib.patches import Patch

legend_elements = [
    Patch(facecolor='blue', alpha=0.7, label='–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'),
    Patch(facecolor='green', alpha=0.7, label='–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ'),
    Patch(facecolor='red', alpha=0.7, label='–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã'),
    Patch(facecolor='purple', alpha=0.7, label='RAG'),
    Patch(facecolor='gray', alpha=0.7, label='–î—Ä—É–≥–æ–µ')
]

plt.legend(handles=legend_elements, loc='upper right')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥—Ä–∞—Ñ–∏–∫–∞
plt.title('–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: –ø–æ—Ö–æ–∂–∏–µ —Ç–µ–º—ã —Ä—è–¥–æ–º', fontsize=14, pad=20)
plt.xlabel('–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1', fontsize=12)
plt.ylabel('–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2', fontsize=12)
plt.grid(True, alpha=0.3)

# –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—è—Å–Ω–µ–Ω–∏—è
plt.figtext(0.5, 0.01,
            'üìå –ö–∞–∂–¥–∞—è —Ç–æ—á–∫–∞ = –æ–¥–∏–Ω —á–∞–Ω–∫ —Ç–µ–∫—Å—Ç–∞\n'
            'üìå –ë–ª–∏–∑–∫–∏–µ —Ç–æ—á–∫–∏ = –ø–æ—Ö–æ–∂–∏–µ –ø–æ —Å–º—ã—Å–ª—É —Ç–µ–∫—Å—Ç—ã\n'
            'üìå –î–∞–ª–µ–∫–∏–µ —Ç–æ—á–∫–∏ = —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã\n'
            'üìå PCA –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Ç–µ–º—ã',
            ha='center', fontsize=10, style='italic', bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue"))

plt.tight_layout(rect=[0, 0.05, 1, 0.95])

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º
plt.savefig('embeddings_visualization.png', dpi=150, bbox_inches='tight')
print("\n‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'embeddings_visualization.png'")
print("\n–û—Ç–∫—Ä–æ–π—Ç–µ —Ñ–∞–π–ª, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è!")

# –ú–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ –±–ª–æ–∫–Ω–æ—Ç–µ:
# plt.show()

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —à–∞–≥–∞
print("\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞...")
rag_data["embeddings"] = embeddings
rag_data["embeddings_2d"] = embeddings_2d
rag_data["pca_model"] = pca

print("\n" + "=" * 60)
print("–ò–¢–û–ì –≠–¢–ê–ü–ê 2:")
print("=" * 60)
print("‚úÖ –°–æ–∑–¥–∞–ª–∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤")
print("‚úÖ –ù–∞—É—á–∏–ª–∏—Å—å –≤—ã—á–∏—Å–ª—è—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ")
print("‚úÖ –£–≤–∏–¥–µ–ª–∏, —á—Ç–æ –ø–æ—Ö–æ–∂–∏–µ —Ç–µ–º—ã –≥—Ä—É–ø–ø–∏—Ä—É—é—Ç—Å—è –≤–º–µ—Å—Ç–µ")
print("‚úÖ –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Ä–∞–±–æ—Ç—ã –∞–ª–≥–æ—Ä–∏—Ç–º–∞")
print("\n–¢–µ–ø–µ—Ä—å –º–æ–∂–µ–º –∏—Å–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Å–º—ã—Å–ª—É!")


with open('rag_data_step2.pkl', 'wb') as f:
    pickle.dump(rag_data, f)

print("\nüíæ –î–∞–Ω–Ω—ã–µ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'rag_data_step2.pkl'")
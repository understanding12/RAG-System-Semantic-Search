"""
rag_interactive_real.py - –ù–ê–°–¢–û–Ø–©–ê–Ø RAG –°–ò–°–¢–ï–ú–ê
–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
"""

print("=" * 70)
print("ü§ñ –ù–ê–°–¢–û–Ø–©–ê–Ø RAG –°–ò–°–¢–ï–ú–ê")
print("=" * 70)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
import pickle
import numpy as np

try:
    with open('rag_data_step3.pkl', 'rb') as f:
        rag_data = pickle.load(f)

    print("‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

    chunks = rag_data["chunks"]
    chunk_info = rag_data["chunk_info"]
    embeddings = rag_data["embeddings"]

    print(f"üìö –í –±–∞–∑–µ: {len(chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")

except FileNotFoundError:
    print("‚ùå –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    exit()


def calculate_similarity(vec1, vec2):
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)

    if norm1 == 0 or norm2 == 0:
        return 0
    return dot_product / (norm1 * norm2)


def ask_rag_real(question):
    """
    –ù–ê–°–¢–û–Ø–©–ê–Ø RAG: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
    """
    print(f"\nüîç –ò—â—É –æ—Ç–≤–µ—Ç –Ω–∞: '{question}'")

    # 1. –ü–û–ò–°–ö (–∫–∞–∫ —Ä–∞–Ω—å—à–µ, –Ω–æ —É–ª—É—á—à–µ–Ω–Ω—ã–π)
    query_words = question.lower().split()
    query_embedding = np.zeros(embeddings.shape[1])
    matching_chunks = 0

    for i, chunk in enumerate(chunks):
        chunk_lower = chunk.lower()
        if any(word in chunk_lower for word in query_words):
            query_embedding += embeddings[i]
            matching_chunks += 1

    if matching_chunks > 0:
        query_embedding /= matching_chunks
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å–ª–æ–≤, –∏—â–µ–º –ø–æ —Å–º—ã—Å–ª—É
        for i, chunk_embedding in enumerate(embeddings):
            query_embedding += chunk_embedding
        query_embedding /= len(embeddings)

    # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —á–∞–Ω–∫–∏
    similarities = []
    for i, chunk_embedding in enumerate(embeddings):
        similarity = calculate_similarity(query_embedding, chunk_embedding)
        similarities.append((i, similarity))

    similarities.sort(key=lambda x: x[1], reverse=True)
    top_results = similarities[:3]  # –ë–µ—Ä–µ–º 3 –ª—É—á—à–∏—Ö

    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(top_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤:")
    for rank, (idx, similarity) in enumerate(top_results, 1):
        print(f"  #{rank} (—Å—Ö–æ–¥—Å—Ç–≤–æ: {similarity:.3f})")
        print(f"    {chunks[idx][:80]}...")

    # 2. –§–û–†–ú–ò–†–£–ï–ú –ü–†–û–ú–ü–¢ –° –ù–ê–ô–î–ï–ù–ù–´–ú–ò –§–†–ê–ì–ú–ï–ù–¢–ê–ú–ò
    print("\nüìù –§–æ—Ä–º–∏—Ä—É—é –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞...")

    # –°–æ–±–∏—Ä–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
    context_parts = []
    for rank, (idx, similarity) in enumerate(top_results, 1):
        context_parts.append(f"[–ò—Å—Ç–æ—á–Ω–∏–∫ #{rank}, —Å—Ö–æ–¥—Å—Ç–≤–æ: {similarity:.3f}]:")
        context_parts.append(chunks[idx])
        context_parts.append("")

    context = "\n".join(context_parts)

    # –ü—Ä–æ–º–ø—Ç –¥–ª—è "–≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π LLM"
    prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–§–†–ê–ì–ú–ï–ù–¢–´ –¢–ï–ö–°–¢–ê:
{context}

–í–û–ü–†–û–°: {question}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤—ã—à–µ
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —Å–∫–∞–∂–∏ "–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –º–æ–≥—É –¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç"
3. –ë—É–¥—å —Ç–æ—á–Ω—ã–º –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º
4. –£–∫–∞–∂–∏, –∏–∑ –∫–∞–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (#–Ω–æ–º–µ—Ä–∞) —Ç—ã –±–µ—Ä–µ—à—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

–û–¢–í–ï–¢:"""

    # 3. "–ì–ï–ù–ï–†–ê–¶–ò–Ø" –û–¢–í–ï–¢–ê (–∏–º–∏—Ç–∞—Ü–∏—è LLM)
    # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –≤—ã–∑–æ–≤ ChatGPT:
    # import openai
    # response = openai.ChatCompletion.create(...)

    print("\nü§ñ –ì–ï–ù–ï–†–ò–†–£–Æ –û–¢–í–ï–¢ –ù–ê –û–°–ù–û–í–ï –ù–ê–ô–î–ï–ù–ù–´–• –§–†–ê–ì–ú–ï–ù–¢–û–í...")
    print("-" * 50)

    # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ
    answer_parts = []

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
    relevant_info = []
    sources_used = []

    for rank, (idx, similarity) in enumerate(top_results, 1):
        if similarity > 0.5:  # –ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            chunk_text = chunks[idx]

            # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑: —á—Ç–æ –≤ —ç—Ç–æ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ –ø–æ–ª–µ–∑–Ω–æ–≥–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞?
            if any(word in question.lower() for word in ["–º–∞—à–∏–Ω–Ω", "ml", "machine"]):
                if "–º–∞—à–∏–Ω–Ω" in chunk_text.lower():
                    relevant_info.append(chunk_text)
                    sources_used.append(rank)

            elif any(word in question.lower() for word in ["–≥–ª—É–±–æ–∫", "deep"]):
                if "–≥–ª—É–±–æ–∫" in chunk_text.lower():
                    relevant_info.append(chunk_text)
                    sources_used.append(rank)

            elif any(word in question.lower() for word in ["—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä", "gpt", "bert"]):
                if any(word in chunk_text.lower() for word in ["—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä", "gpt", "bert", "t5"]):
                    relevant_info.append(chunk_text)
                    sources_used.append(rank)

            elif any(word in question.lower() for word in ["rag", "retrieval"]):
                if "rag" in chunk_text.lower():
                    relevant_info.append(chunk_text)
                    sources_used.append(rank)
            else:
                # –î–ª—è –æ–±—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –±–µ—Ä–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —Å—Ö–æ–¥—Å—Ç–≤–æ–º
                if rank == 1:
                    relevant_info.append(chunk_text)
                    sources_used.append(rank)

    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    if relevant_info:
        answer_parts.append("–ù–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:")
        answer_parts.append("")

        for i, info in enumerate(relevant_info[:2]):  # –ë–µ—Ä–µ–º –Ω–µ –±–æ–ª–µ–µ 2 —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
            # –£–ø—Ä–æ—â–∞–µ–º –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            sentences = info.replace('\n', ' ').split('. ')
            key_sentences = [s for s in sentences if len(s) > 20][:3]  # –ü–µ—Ä–≤—ã–µ 3 –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è

            answer_parts.append(f"{'. '.join(key_sentences)}.")
            answer_parts.append("")

        answer_parts.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫–∏: #{', #'.join(map(str, sources_used))}")
    else:
        answer_parts.append("–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞—à–µ–ª –ø—Ä—è–º–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.")
        answer_parts.append("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞—Ç—å –æ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏, –≥–ª—É–±–æ–∫–æ–º –æ–±—É—á–µ–Ω–∏–∏, —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞—Ö –∏–ª–∏ RAG —Å–∏—Å—Ç–µ–º–∞—Ö.")

    answer = "\n".join(answer_parts)
    print(answer)
    print("-" * 50)

    # 4. –ü–û–ö–ê–ó–´–í–ê–ï–ú, –ß–¢–û –ò–°–ü–û–õ–¨–ó–û–í–ê–õ–û–°–¨
    print("\nüìö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´:")
    for rank, (idx, similarity) in enumerate(top_results, 1):
        if rank in sources_used:
            doc_title = chunk_info[idx]["doc_title"]
            print(f"  ‚Ä¢ {doc_title} (–∏—Å—Ç–æ—á–Ω–∏–∫ #{rank}, —Å—Ö–æ–¥—Å—Ç–≤–æ: {similarity:.3f})")


# –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
print("""
ü§ñ –ù–ê–°–¢–û–Ø–©–ê–Ø RAG –°–ò–°–¢–ï–ú–ê

–û—Ç–ª–∏—á–∏–µ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏:
‚úÖ –ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
‚úÖ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Ö —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
‚úÖ –§–æ—Ä–º–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –ù–ê –û–°–ù–û–í–ï –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ
‚úÖ –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≥–æ—Ç–æ–≤—ã–µ —à–∞–±–ª–æ–Ω—ã

–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã:
""")

while True:
    print("\n" + "=" * 50)
    question = input("\n‚ùì –í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()

    if question.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit', 'q']:
        print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
        break

    if not question:
        continue

    try:
        ask_rag_real(question)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")